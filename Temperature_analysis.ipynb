{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab5e500",
   "metadata": {},
   "source": [
    "# The Impact of Ambient Temperature on Server Efficiency\n",
    "\n",
    "\n",
    "Hypothesis: Server power consumption increases as temperature increases reducing server efficiency. As PUE values approach 1 an increasing portion of the Data centre's power is used in the server therfore there is likely to be a trade-off on operating temperature depending on cooling infrastructure and number of servers in the datacenter. \n",
    "\n",
    "------\n",
    "\n",
    "Plan:\n",
    "\n",
    "- Load in all of the SERT results avoiding any invalid ones\n",
    "- Merge data as needed \n",
    "- Generate graphs showing power consumption against load and temperature\n",
    "- Find a trade-off between operating temperature and number of servers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2acf4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os.path\n",
    "from os import makedirs\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from parse_results import process_results_xml\n",
    "import yaml\n",
    "#import influxdb_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0faa2f6",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('settings.yaml'):\n",
    "    with open('settings.yaml', 'r') as f:\n",
    "        params = yaml.load(f, Loader=yaml.FullLoader)\n",
    "else:\n",
    "    params = {}\n",
    "    \n",
    "sert_results_dir = params.get('results_dir', 'sert_results')\n",
    "bios_setting_file = params.get('test_settings', 'test_settings.csv')\n",
    "cpu_metrics_dir = params.get('cpu_metrics_dir', 'cpu_data')\n",
    "\n",
    "working_dir = params.get('temp_dir', 'temp_dir')\n",
    "all_data_file = params.get('data_file', 'all_data.csv')\n",
    "overwrite_data = params.get('overwrite_data', False)\n",
    "\n",
    "overwrite_data = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ecedf",
   "metadata": {},
   "source": [
    "# Generate and load the data (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bafcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sert_data = pd.DataFrame()\n",
    "\n",
    "if not os.path.isdir(working_dir):\n",
    "    os.makedirs(working_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "if not os.path.isfile(f'{working_dir}//{all_data_file}') or overwrite_data:\n",
    "\n",
    "    metrics_data = pd.DataFrame()\n",
    "    test_details = pd.DataFrame()\n",
    "    scores = pd.DataFrame()\n",
    "    invalid_results = []   # List of skipped results because they're invalid\n",
    "\n",
    "    for f in glob.glob(f'{sert_results_dir}//**//results.xml', recursive=True):\n",
    "        try:\n",
    "            # Name of test directory -- sert-xxxx\n",
    "            test_name = os.path.basename(os.path.dirname(f))\n",
    "\n",
    "            if os.path.isfile(f'{sert_results_dir}//{test_name}//invalid.png'):\n",
    "                invalid_results.append(test_name)\n",
    "                continue\n",
    "            \n",
    "            # Load the SERT result\n",
    "            metrics, score, env = process_results_xml(f)\n",
    "\n",
    "            file_df = pd.DataFrame.from_records(metrics)\n",
    "            # Remove calibration runs but record the calibration score against each loadlevel to calculate actual loadlevel\n",
    "            calibrations = file_df.loc[file_df['loadlevel']=='calibration', ['worklet', 'score']]\n",
    "            calibrations = calibrations.rename(columns={'score': 'calibration-score'})\n",
    "\n",
    "            file_df = pd.merge(file_df.drop(index=calibrations.index), calibrations, how='left', on='worklet')\n",
    "            file_df['actual-load'] = file_df['score'] / file_df['calibration-score']\n",
    "            file_df['test-name'] = test_name\n",
    "\n",
    "            score_df = pd.DataFrame.from_records(score)\n",
    "            score_df['test-name'] = test_name\n",
    "\n",
    "            metrics_data = metrics_data.append(file_df, ignore_index=True)\n",
    "            test_details = test_details.append(pd.DataFrame.from_records(env, index=[test_name]))\n",
    "            scores = scores.append(score_df, ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f, ': FAILED TO LOAD -- ', e, type(e))\n",
    "    \n",
    "    if len(invalid_results) > 0:    \n",
    "        print(f'Invalid results skipped: {invalid_results}')\n",
    "\n",
    "    # Load external details for test\n",
    "    if bios_setting_file != '' and os.path.isfile(bios_setting_file):\n",
    "        settings = pd.read_csv(bios_setting_file, index_col=0)\n",
    "    else:\n",
    "        settings = pd.DataFrame()\n",
    "    #settings.columns = ['location', 'bios']\n",
    "    test_details = pd.merge(test_details, settings, left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Join metrics and test details to results.\n",
    "    sert_data = pd.merge(metrics_data, scores, how='left', on=['test-name', 'worklet', 'loadlevel', 'workload', 'score', 'watts-avg'])\n",
    "    sert_data = pd.merge(sert_data, test_details, left_on='test-name', right_index=True)\n",
    "    sert_data.loc[sert_data['workload'] == 'Idle', 'actual-load'] = 0\n",
    "    \n",
    "    #Pressure lookup here for tunnel tests\n",
    "    if 'influxdb' in params:\n",
    "        from influxdb import InfluxDBClient\n",
    "        client = InfluxDBClient(host=params['influxdb']['host'], \n",
    "                                port=params['influxdb']['port'], \n",
    "                                username=params['influxdb']['user'], \n",
    "                                password=params['influxdb']['password'],\n",
    "                                database=params['influxdb']['tunnel-database'])\n",
    "\n",
    "        def pressure_func(r):\n",
    "            if r.location == 'Tunnel':\n",
    "                query = f'select (mean(\"value\")-21.65)*62/19 from sensors where \"channel\"=\\'Pressure\\' and time>=\\'{r.start.isoformat()}\\' and time<=\\'{r.end.isoformat()}\\''\n",
    "                result = client.query(query)\n",
    "                for pt in result.get_points('sensors'):\n",
    "                    return pt['mean']\n",
    "\n",
    "                return np.nan # Tunnel run but no data\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        sert_data['pressure'] = sert_data.apply(pressure_func, axis=1)\n",
    "\n",
    "    # Store generated data\n",
    "    metrics_data.to_csv(f'{working_dir}//sert_metrics.csv', index=False)\n",
    "    test_details.to_csv(f'{working_dir}//test_details.csv')\n",
    "    scores.to_csv(f'{working_dir}//scores.csv', index=False)\n",
    "    sert_data.to_csv(f'{working_dir}//{all_data_file}', index=False)\n",
    "    \n",
    "else:\n",
    "    print(f'Loading SERT data from disk')\n",
    "    sert_data = pd.read_csv(f'{working_dir}//{all_data_file}', parse_dates=['start', 'end'])\n",
    "    scores = pd.read_csv(f'{working_dir}//scores.csv')\n",
    "    test_details = pd.read_csv(f'{working_dir}//test_details.csv', index_col=0)        \n",
    "    \n",
    "sert_data['scenario'] = list(' - '.join(s) for s in zip(sert_data['model'], sert_data['cpu']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c305ab3c-883d-46d1-84aa-96e71157e29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sert_data.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d9b84-2280-4cd1-822f-367bffc439f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sert_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b687bc-a3fd-43e5-ae41-7c62707d1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_details\n",
    "total_score = scores[scores['workload'] == 'All'].dropna(axis=1)\n",
    "total_score = total_score.merge(test_details, left_on='test-name', right_index=True, how='left').dropna()\n",
    "total_score['scenario'] = list(' - '.join(x) for x in zip(total_score['model'], total_score['cpu']))\n",
    "total_score['temperature'] = total_score.apply(lambda row: sert_data[sert_data['test-name'] == row['test-name']]['temp-avg'].mean(), axis=1)\n",
    "total_score['temperature-range'] = total_score.apply(lambda row: sert_data[sert_data['test-name'] == row['test-name']]['temp-max'].max() - sert_data[sert_data['test-name'] == row['test-name']]['temp-min'].min(), axis=1)\n",
    "total_score = total_score.merge(sert_data[sert_data['workload'] == 'Idle'][['watts-avg','test-name']], left_on='test-name', right_on='test-name').rename(columns={'watts-avg':'idle-power'})\n",
    "total_score['max-power'] = total_score.apply(lambda row: sert_data[(sert_data['test-name'] == row['test-name']) & (sert_data['loadlevel']=='100%')]['watts-avg'].mean(), axis=1)\n",
    "total_score['pressure'] = total_score.apply(lambda row: sert_data[sert_data['test-name'] == row['test-name']]['pressure'].mean(), axis=1)\n",
    "total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c649306-1ffd-422d-a061-b7abc1a9b52c",
   "metadata": {},
   "source": [
    "# What scenarios have been tested?\n",
    "Using a 3 bin strategy for temperature testing and high and low for pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb14c80-525a-4b43-8393-cb09270a008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = total_score.groupby(['scenario', 'bios', pd.cut(total_score.pressure, [total_score.pressure.min(), 15, total_score.pressure.max()]), pd.cut(total_score.temperature,[20, 23.5,27.5, 30])]).size().unstack().unstack()\n",
    "tested.style.applymap(lambda x: 'background-color:pink' if x < 3 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa04455-9e9a-47c2-920f-d8afca496356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean\\n', sert_data.groupby('scenario')['temp-avg'].mean())\n",
    "print('\\nVariance\\n', sert_data.groupby('scenario')['temp-avg'].var())\n",
    "sns.displot(data=sert_data, x=\"temp-avg\", hue=\"scenario\", kde=True, fill=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5bdb0-05f1-44ed-b43b-48b709985a57",
   "metadata": {},
   "source": [
    "# Effects on overall SERT score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c214ef",
   "metadata": {},
   "source": [
    "# Efficiency and power consumption measured by SERT\n",
    "\n",
    "For the CPU workelts in particular, we can plot the benchmark load against the efficiency score achevied for each scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = sert_data[(sert_data['workload'] == 'CPU')| (sert_data['workload'] == 'Idle')]\n",
    "\n",
    "sns.lmplot(x='actual-load', y='efficiency-score', hue='scenario', col='bios', \n",
    "           data=cpu[cpu['temp-avg'] < 23.5], order=2, truncate=True, scatter=True).fig.suptitle('CPU Worklet Efficiency Scores', y=1.1)\n",
    "sns.lmplot(x='actual-load', y='watts-avg', hue='scenario', col='bios', \n",
    "           data=cpu[cpu['temp-avg'] < 23.5], order=2, truncate=True, scatter=True).fig.suptitle('CPU Worklet Power Consumption', y=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512c31a8",
   "metadata": {},
   "source": [
    "A cleaner plot without the individual data plotted for each sert run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fcfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='actual-load', y='efficiency-score', hue='scenario', data=cpu[cpu['temp-avg'] < 22.5], order=2, truncate=True, scatter=False)\n",
    "ax = plt.gca()\n",
    "ax.set_title('CPU Worklet Efficiency Scores ( Test Temperature < 22.5C)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b12c8",
   "metadata": {},
   "source": [
    "The environmental conditions for the tests are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344110b6-92bd-4bf0-87cb-460f7caa1513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bea7551-6012-4b77-98b0-561ef7fddf9d",
   "metadata": {},
   "source": [
    "# The Effect of Temperature\n",
    "The overall efficiency score across various temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8d6d1-a15e-4099-9b8d-cba95fe06fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=total_score, x='temperature', y='efficiency-score', hue='scenario', col='bios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7c035-f14b-4134-af85-452b4f4eeab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score[total_score['temperature'] < 22].groupby(['scenario', 'bios'])[['efficiency-score', 'temperature', 'idle-power', 'max-power']].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bcd765-a071-4f97-91bd-a7a57b20233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_score[total_score['temperature'] > 28].groupby(['scenario', 'bios'])[['efficiency-score', 'temperature', 'idle-power', 'max-power']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740389b-74c2-4b1a-9144-a169d6ee009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu[(cpu['loadlevel'] == '100%')].groupby([ 'worklet','scenario', 'bios'])['norm-score'].mean().unstack().pct_change(axis=1).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a9bc4-ed72-416b-9aa0-26643c6d5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu[(cpu.model == 'PowerEdge R640') & (cpu.worklet == 'CryptoAES') & (cpu.loadlevel == '100%')].groupby('bios')['norm-score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a19460-95cf-4669-be37-24f1609d9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu[['worklet', 'loadlevel', 'scenario', 'bios', 'score']].groupby(['scenario', 'bios', 'worklet', 'loadlevel']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b28bf-9ac9-4c97-9e7f-046dd4407e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf715ba",
   "metadata": {},
   "source": [
    "# CPU Power\n",
    "\n",
    "The CPU is usually considered the driver of most power consumption in the server (excluding any expansion cards). During the SERT tests we have also recorded low-level performance registers of the CPU like per-core frequency and also power consumption. \n",
    "\n",
    "Todo: \n",
    "- Determine relationship between chassis and CPU power consumption\n",
    "    - Assume power = P_Idle + P_Chassis + P_CPU\n",
    "    - IS P_Chassis a function of CPU power?\n",
    "    \n",
    "    \n",
    "Read the CPU power data in and summarise for the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdce9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_metrics = pd.DataFrame()\n",
    "\n",
    "if not os.path.exists(f'{working_dir}//cpu_metrics.csv') or overwrite_data :\n",
    "    \n",
    "    for f in glob.glob(f'{cpu_metrics_dir}//**.csv', recursive=True):\n",
    "        try:\n",
    "            samples = pd.read_csv(f, skiprows=8, header=0, index_col=0, parse_dates=['Time'], encoding='cp1252')\n",
    "            if not pd.api.types.is_datetime64_any_dtype(samples.index.dtype):\n",
    "                # Final row contains \"Session end:\"\n",
    "                samples.drop('Session end:', inplace=True)\n",
    "                samples.index = pd.to_datetime(samples.index)\n",
    "\n",
    "            cpu_metrics = cpu_metrics.append(samples)\n",
    "        except:\n",
    "            print(f'FAILED LOADING FILE: {f}')\n",
    "\n",
    "    cpu_metrics.sort_index(inplace=True)\n",
    "    cpu_metrics['total cpu power'] = cpu_metrics['CPU 0 Power'] + cpu_metrics['CPU 1 Power']\n",
    "    \n",
    "    cpu_metrics.to_csv(f'{working_dir}//cpu_metrics.csv')\n",
    "    \n",
    "else:\n",
    "    cpu_metrics = pd.read_csv(f'{working_dir}//cpu_metrics.csv', index_col='Time', parse_dates=['Time'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b119c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_metrics['avg-temp'] = cpu_metrics.filter(regex='Temp').mean(axis=1, skipna=True)\n",
    "cpu_metrics['avg-load'] = cpu_metrics.filter(regex='load').mean(axis=1, skipna=True)\n",
    "cpu_metrics['avg-freq'] = cpu_metrics.filter(regex='speed').mean(axis=1, skipna=True)\n",
    "\n",
    "\n",
    "#pd.to_datetime(cpu_metrics['Time']\n",
    "sert_data['cpu-power'] = sert_data.apply(lambda row: cpu_metrics['total cpu power'][row['start'].tz_localize(None):row['end'].tz_localize(None)].mean(), axis=1)\n",
    "sert_data['chassis-power'] = sert_data['watts-avg'] - sert_data['cpu-power']\n",
    "\n",
    "sert_data['cpu-temp'] = sert_data.apply(lambda row: cpu_metrics['avg-temp'][row['start'].tz_localize(None):row['end'].tz_localize(None)].mean(), axis=1)\n",
    "sert_data['cpu-load'] = sert_data.apply(lambda row: cpu_metrics['avg-load'][row['start'].tz_localize(None):row['end'].tz_localize(None)].mean(), axis=1)\n",
    "sert_data['cpu-freq'] = sert_data.apply(lambda row: cpu_metrics['avg-freq'][row['start'].tz_localize(None):row['end'].tz_localize(None)].mean(), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031968c",
   "metadata": {},
   "source": [
    "Looking again at the server efficiency scores, but now using the CPU utilsiation dat from the OS rather than the load data calculated by SERT. SERT load is a proportion of the total score/transactions acheived during the calibration runs. OS CPU utilisaiton is the proportion of time the CPU is busy performing operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_worklets = sert_data[(sert_data['workload'] == 'Idle') | (sert_data['workload'] == 'CPU')]\n",
    "cpu_worklets['scenario'] = list(' - '.join(x) for x in zip(cpu_worklets['model'], cpu_worklets['cpu']))\n",
    "sns.lmplot(x='cpu-load', y='efficiency-score', hue='scenario', col='bios', data=cpu_worklets[cpu_worklets['temp-avg'] < 22.5], order=2, truncate=True, scatter=True).fig.suptitle('Efficiency Scores ( Test Temperature < 22.5C)', y=1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93081c2b",
   "metadata": {},
   "source": [
    "This is a significantly different relationship than that shown for the SERT load. \n",
    "\n",
    "Breaking down the performance per server and per worklet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fdfcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    sns.lmplot(x='cpu-load', y='watts-avg', hue='worklet', col='bios', row='scenario', data=cpu_worklets, order=1, truncate=True, scatter=True).fig.suptitle(f'Efficiency Scores', y=1.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ed774-550c-4849-827e-6f7e6b191977",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='temp-avg', y='efficiency-score', hue='scenario', data=cpu_worklets, order=1, scatter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aef965",
   "metadata": {},
   "source": [
    "# CPU power consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdf = cpu_worklets.melt('actual-load', ['watts-avg', 'cpu-power', 'chassis-power'])\n",
    "\n",
    "sns.lmplot(x='actual-load', y='value', hue='variable', data=plotdf, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "for server in cpu_worklets['scenario'].unique():\n",
    "    plotdf = cpu_worklets[cpu_worklets['scenario'] == server].melt(['actual-load', 'bios'], ['watts-avg', 'cpu-power', 'chassis-power'])\n",
    "\n",
    "    sns.lmplot(x='actual-load', y='value', col='bios', hue='variable', data=plotdf, order=2).fig.suptitle(f'Power Breakdown - {server}', y=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee182f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for server in cpu_worklets['scenario'].unique():\n",
    "    plotdf = cpu_worklets[cpu_worklets['scenario'] == server].melt(['cpu-load', 'bios'], ['watts-avg', 'cpu-power', 'chassis-power'])\n",
    "\n",
    "    sns.lmplot(x='cpu-load', y='value', col='bios', hue='variable', data=plotdf, order=2).fig.suptitle(f'Power Breakdown - {server}', y=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for worklet in sert_data[sert_data['workload'] == 'CPU']['worklet'].unique():\n",
    "    sns.lmplot(data=sert_data[(sert_data['worklet'] == worklet) | (sert_data['workload'] == 'Idle')], x='actual-load', y='cpu-load', hue='scenario', col='bios', order=2).fig.suptitle(f'Server load vs CPU utilisaiton - {worklet}', y=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = sert_data[(sert_data['workload'] == 'CPU')| (sert_data['workload'] == 'Idle')]\n",
    "cpu = cpu[cpu['model'] == 'PowerEdge R620']\n",
    "#cpu = cpu[cpu['cpu'].str.contains('E5-2690 0')]\n",
    "\n",
    "\n",
    "#sns.lmplot(x='cpu-power', y='chassis-power', hue='worklet', data=cpu, order=2)\n",
    "sns.scatterplot(x='temp-avg', y='watts-avg', hue='cpu', data=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26498c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cddb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='cpu-load', y='cpu-power', data=cpu, order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d74e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.scatter(x=cpu['cpu-temp'], y=cpu['cpu-power'], c=cpu['temp-avg'])\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('Ambient Temp', rotation=90)\n",
    "plt.ylabel('CPU Power')\n",
    "plt.xlabel('CPU Temp')\n",
    "plt.title('R620 E5-2690, Efficiency (DPAC) Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.scatter(x=cpu['cpu-temp'], y=cpu['cpu-power'], c=cpu['cpu-load'])\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('CPU Load', rotation=90)\n",
    "plt.ylabel('CPU Power')\n",
    "plt.xlabel('CPU Temp')\n",
    "plt.title('R620 E5-2690, Efficiency (DPAC) Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f874860",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.scatter(x=cpu['cpu-freq'], y=cpu['cpu-power'], c=cpu['cpu-load'])\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_ylabel('CPU Load', rotation=90)\n",
    "plt.ylabel('CPU Power')\n",
    "plt.xlabel('CPU Freq')\n",
    "plt.title('R620 E5-2690, Efficiency (DPAC) Mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cc64a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
